---
title: "Beyond consistency: Contextual dependency of language style in monologue and
  conversation"
output:
  html_document:
    keep_md: yes
    number_sections: yes

---

This R markdown provides the data preparation for our forthcoming manuscript.

To run this from scratch, you will need the following files:

* [This is where a description of the data setup goes]
* `./scripts/bc-libraries_and_functions.r`: Loads in necessary libraries and
creates new functions for our analyses.

**Code written by**: L. C. Mueller-Frommeyer (Technische Universitaet 
Braunschweig) & A. Paxton (University of Connecticut)

**Date last modified**: 12 June 2019

```{r silent-setup, include=FALSE}

# cache our results
library(knitr)
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE, cache.lazy=FALSE)

```

***

# Preliminaries

```{r prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear everything
rm(list=ls())

# load libraries and add new functions
source('./scripts/bc-libraries_and_functions.r')

```

***

# Hypothesis 1

***

## Data preparation

***

### Monologues

```{r monologue-load-data}

# read in all monologue files
mon_files = list.files('./data/LIWC-results/RQA/Monologues', 
                       pattern = ".txt", full.names = TRUE)
mon_dfs = plyr::ldply(mon_files, 
                      read.table, sep="\t", dec = ",", header=TRUE) #added decimal to get numbers instead of characters

```

```{r monologue-prepare-for-rqa}

# prepare monologues for RQA
mon_dfs = mon_dfs %>% 
  
  # separate 'Filename' column into separate columns
  tidyr::separate(Filename, 
                  into = c("dyad_id", "dyad_position", "speaker_code"), 
                  sep = '_', 
                  remove = FALSE, 
                  extra = "drop", 
                  fill = "warn") %>%
  
  # extract speaker number ID and conversation type from variable
  mutate(cond = gsub("[[:digit:]]+","",dyad_id)) %>%
  
  # create new variable function_contrast with all 0 replaced by -1
  dplyr::rename(function_words = function.) %>%
  mutate(function_contrast = dplyr::if_else(function_words==0,
                                            -1,
                                            function_words)) %>%
  
  #add new variable specifying conversation type
  mutate(conv.type = "M")

```

```{r monologues-rqa}

# split dataframe by monologue
split_mon = split(mon_dfs, list(mon_dfs$Filename))

# cycle through the individual monologues
crqa_results_mon = data.frame()
for (next_mon in split_mon){
  
  # run (auto-)recurrence
  rqa_for_mon = crqa(ts1=next_mon$function_words,
                     ts2=next_mon$function_contrast,
                     delay=1,
                     embed=1,
                     r=0.1,
                     normalize=0, 
                     rescale=0, 
                     mindiagline=2,
                     minvertline=2, 
                     tw=1, # exclude line of identity
                     whiteline=FALSE,
                     recpt=FALSE)
  
  # save plot-level information to dataframe
  dyad_id = unique(next_mon$dyad_id)
  speaker_code = unique(next_mon$speaker_code)
  cond = unique(next_mon$cond)
  conv.type = unique(next_mon$conv.type)
  next_data_line = data.frame(dyad_id,  
                              speaker_code,
                              conv.type,
                              rqa_for_mon[1:9])
  crqa_results_mon = rbind.data.frame(crqa_results_mon,next_data_line)
}

# add column names
colnames(crqa_results_mon) <- paste(colnames(crqa_results_mon), "M", sep = "_")

```

***

### Conversations

```{r conversations-load-data}

# read in all conversation files
conv_files = list.files('./data/LIWC-results/RQA/Conversations-1', 
                        pattern = ".txt", full.names = TRUE)
conv_dfs = plyr::ldply(conv_files, 
                       read.table, sep="\t", dec = ",", header=TRUE) 

```

```{r conversations-prepare-for-crqa}

# prepare conversations for CRQA
conv_dfs = conv_dfs %>% 
  
  # separate 'Filename' column into separate columns
  tidyr::separate(Filename, 
                  into = c("dyad_id", "dyad_position", "speaker_code"), 
                  sep = '_', 
                  remove = FALSE, 
                  extra = "drop", 
                  fill = "warn") %>%
  
  # extract speaker number ID and conversation type from variable
  mutate(cond = gsub("[[:digit:]]+","",dyad_id)) %>%
  
  # create new variable function_contrast with all 0 replaced by -1
  dplyr::rename(function_words = function.) %>%
  mutate(function_contrast = dplyr::if_else(function_words==0,
                                            -1,
                                            function_words)) %>%
  
  # add new variable specifying conversation type
  mutate(conv.type = "C")

```

```{r conversations-crqa}

# split dataframe by conversation
split_conv = split(conv_dfs, list(conv_dfs$Filename))

# cycle through the individual conversations
crqa_results_conv = data.frame()
for (next_conv in split_conv){
  
  # run cross-recurrence
  rqa_for_conv = crqa(ts1=next_conv$function_words,
                      ts2=next_conv$function_contrast,
                      delay=1,
                      embed=1,
                      r=0.1,
                      normalize=0, 
                      rescale=0, 
                      mindiagline=2,
                      minvertline=2, 
                      tw=0,
                      whiteline=FALSE,
                      recpt=FALSE)
  
  # save plot-level information to dataframe
  dyad_id = unique(next_conv$dyad_id)
  speaker_code = unique(next_conv$speaker_code)
  conv.type = unique(next_conv$conv.type)
  cond = unique(next_conv$cond)
  next_data_line = data.frame(dyad_id,  
                              speaker_code,
                              conv.type,
                              cond,
                              rqa_for_conv[1:9])
  crqa_results_conv = rbind.data.frame(crqa_results_conv,next_data_line)
}

# add column names
colnames(crqa_results_conv) <- paste(colnames(crqa_results_conv), "C", sep = "_")

```

### Combine monologues and dialogues

```{r create-h1-dataframe}

# bring together the monologue and conversation data
h1_data = cbind(crqa_results_mon, crqa_results_conv)
#write.table(h1_data, file = 'C:/Users/Lena/Desktop',sep=",") 

```


***

## Data analyses

```{r}

```

*** 

# Hypothesis 2

***

## Data preparation

### Speaker A

```{r}

# get list of Conversation files speaker A
A_files = list.files('./data/LIWC-results/cRQA/SpeakerA', 
                     pattern = ".txt", full.names = TRUE)
A_dfs = plyr::ldply(A_files, 
                    read.table, sep="\t", dec = ",", header=TRUE) #added decimal to get numbers instead of characters

```

```{r}

# prepare conversations Speaker A for RQA
A_dfs = A_dfs %>% ungroup() %>%
  
  # separate 'Filename' column into separate columns
  tidyr::separate(Filename, 
                  into = c("dyad_id", "dyad_position",  "speaker_code"), 
                  sep = '_', 
                  remove = FALSE, 
                  extra = "drop", 
                  fill = "warn") %>%
  
  # extract speaker number ID and conversation type from variable
  mutate(cond = gsub("[[:digit:]]+","",dyad_id)) %>%
  
  # rename function. to function_words
  dplyr::rename(function_words = function.) %>%
  
  # group by participant to cut quantiles
  group_by(Filename) %>%
  
  # recode quartiles
  mutate(fw_quantiles = as.numeric(
    gtools::quantcut(function_words, 
                     q=4, 
                     na.rm = TRUE))
  ) %>% ungroup()

colnames(A_dfs) <- paste(colnames(A_dfs), "A", sep = "_")
```

```{r}
# get list of Conversation files speaker A
B_files = list.files('./data/LIWC-results/cRQA/SpeakerB', 
                     pattern = ".txt", full.names = TRUE)
B_dfs = plyr::ldply(B_files, 
                    read.table, sep="\t", dec = ",", header=TRUE) #added decimal to get numbers instead of characters

```

```{r}

# prepare conversations Speaker A for RQA
B_dfs = B_dfs %>% ungroup() %>%
  
  # separate 'Filename' column into separate columns
  tidyr::separate(Filename, 
                  into = c("dyad_id", "dyad_position",  "speaker_code"), 
                  sep = '_', 
                  remove = FALSE, 
                  extra = "drop", 
                  fill = "warn") %>%
  
  # extract speaker number ID and conversation type from variable
  mutate(cond = gsub("[[:digit:]]+","",dyad_id)) %>%
  
  # rename function. to function_words
  dplyr::rename(function_words = function.) %>%
  
  # group by participant to cut quantiles
  group_by(Filename) %>%
  
  # recode quartiles
  mutate(fw_quantiles = as.numeric(
    gtools::quantcut(function_words, 
                     q=4, 
                     na.rm = TRUE))
  ) %>% ungroup()

colnames(B_dfs) <- paste(colnames(B_dfs), "B", sep = "_")

```

Example code for how to trim the data

```{r}

A_dfs$time <- as.numeric(ave(A_dfs$dyad_id_A, A_dfs$dyad_id_A, FUN=seq_along))
B_dfs$time <- as.numeric(ave(B_dfs$dyad_id_B, B_dfs$dyad_id_B, FUN=seq_along))

df_final <- merge(
  A_dfs, B_dfs,
  by.x=c("dyad_id_A","time"), by.y=c("dyad_id_B","time")
)
#issue 1:sequences are correctly trimmed but the order of sequences is shuffled (1, 10,11,12,...2,20,21...) - is there a way to restore them to 1,2,3,4 etc.?


##your code - did not trim the data set, I marked the issues further down

# this assumes that we're ONLY dealing with 1 conversation per dyad
speaker_As = A_dfs %>% ungroup() %>%
  
  # figure out how many turns each speaker A had
  group_by(dyad_id) %>%
  mutate(max_turns_cond = max(Segment)) %>%
  ungroup() # side note: ALWAYS make sure that you call ungroup() if you group!

# do the same thing for Speaker B
speaker_Bs = B_dfs %>% ungroup() %>%
  
  # figure out how many turns each speaker B had
  group_by(dyad_id) %>%
  mutate(max_turns_cond = max(Segment)) %>%
  ungroup() # side note: ALWAYS make sure that you call ungroup() if you group!

# merge them together
both_speakers = rbind.data.frame(speaker_As, speaker_Bs)
                                 
#issue 2: I added this a a first step because otherweise the frames didn't bind

both_speakers %>% ungroup() %>%
  
  # group by dyad
  group_by(dyad_id) %>%
  
  # figure out how many the maximum is for each dyad
  mutate(trim_turns = min(max_turns_cond)) %>% #
  
  # trim each dyad's to the minimum
  slice(1:unique(trim_turns)) %>%
  ungroup()

#issue 3: now the trim turns variable is not calculated which leads to the data not being trimmed (when the frames are not binded, the trim_turns variable is calculated but useless as it trims A to the length of A)

```

```{r}
# split dataframe by conversation
split_conv = split(df_final, list(df_final$Filename_A))

# cycle through the individual conversations
crqa_results = data.frame()
for (next_conv in split_conv){
  
  # run cross-recurrence
  rqa_for_conv = crqa(ts1=next_conv$fw_quantiles_a,
                      ts2=next_conv$fw_quantiles_b,
                      delay=1,
                      embed=1,
                      r=0.1,
                      normalize=0, 
                      rescale=0, 
                      mindiagline=2,
                      minvertline=2, 
                      tw=1,
                      whiteline=FALSE,
                      recpt=FALSE)
  
  # save plot-level information to dataframe
  dyad_id = unique(next_conv$dyad_id_A)
  cond = unique(next_conv$cond_A)
  next_data_line = data.frame(dyad_id,  
                              cond,
                              rqa_for_conv[1:9])
  crqa_results = rbind.data.frame(crqa_results,next_data_line)
}



# at the end, you should have equal turns per dyad!

# Next, you'll separate speaker A and speaker B from the group dataframe first,
# append the "_A" and "_B" to the relevant columns in each dataframe (function
# words, speaker code, and dyad position), and then join the two together. 
# That will give you everything identical but with two separate columns for 
# each participant's function words.

```


***

### Speaker B


***

### Cross-recurrence quantification analysis

***

# List of next steps

* previous examples
* look over example of using categorical CRQA from emotion dynamics paper: 
https://github.com/a-paxton/emotion-dynamics/blob/master/get_rqa_measures.R
* another useful example will be continuous CRQA in dual conversation constraints paper: https://github.com/a-paxton/dual-conversation-constraints/blob/a167f004c71d9637ec30082de13a1ba6283846bb/dual-conversation-constraints.Rmd#L309 (direct link to line)
#for RQA and CRQA, update so that we have all of the variables we need in the
eventual dataframes (compare with the `mon_dfs` and figure out which to 
preserve)
#fix CRQA based on fixes to RQA today
#add variable to monologue and dialogue dataframes to specify monologue v.
dialogue
* add a step to save the eventual table

* start doing categorical CRQA
* create quartiles of function words -- function `quantile`
* recode 0 appearances of function words as something else (e.g., 0 for one participant, -1 for the other)
* run categorical CRQA with `tw=0` over all of these
* create baseline surrogate measures for H2